{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 01:43:29.997455: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-13 01:43:30.005172: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-13 01:43:30.082486: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-13 01:43:30.198209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-13 01:43:30.317727: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-13 01:43:30.356990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-13 01:43:30.571417: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-13 01:43:32.072624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data import *\n",
    "from utils.datetime import convert_to_pd_timestamp\n",
    "from utils.maps import (location_map, zurich_map, penumbra_map, compactness_map,\n",
    "                        xray_class_map)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor,\n",
    "                              RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import (accuracy_score, mean_squared_error, r2_score, mean_absolute_error,\n",
    "                             precision_score, recall_score, f1_score, confusion_matrix)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:33.302906700Z",
     "start_time": "2024-08-13T00:43:29.387029200Z"
    }
   },
   "id": "d2d09e7563794f0e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/final-merged.csv\")\n",
    "df['Date'] = df['Date'].apply(convert_to_pd_timestamp)\n",
    "df['Is Flare'] = df['Flares Count'].apply(lambda _x: 1 if _x > 0 else 0)\n",
    "# Encoding categorical columns: 'Zurich Class', 'Penumbra Class', 'Compactness Class'\n",
    "label_encoders = {}\n",
    "for col in ['Zurich Class', 'Penumbra Class', 'Compactness Class', 'NS', 'EW', 'X-ray class']:\n",
    "  le = LabelEncoder()\n",
    "  df[col] = le.fit_transform(df[col].astype(str))\n",
    "  label_encoders[col] = le\n",
    "\n",
    "def reverse_labelling(_df):\n",
    "  # Reverse the label encoding\n",
    "  for _col, _le in label_encoders.items():\n",
    "    _df[_col] = _le.inverse_transform(_df[_col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:33.595507200Z",
     "start_time": "2024-08-13T00:43:33.306908600Z"
    }
   },
   "id": "59617361b53a2058"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "columns_for_x = ['Date', 'Total Sunspot', 'Max Size',\n",
    "                 'Zurich Class', 'Penumbra Class', 'Compactness Class',\n",
    "                 'NS', 'Lat', 'EW', 'Lan']\n",
    "\n",
    "X = df[columns_for_x]\n",
    "y_is_flare = df['Is Flare']\n",
    "\n",
    "X_train, X_test, y_is_flare_train, y_is_flare_test = train_test_split(\n",
    "  X, y_is_flare, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:33.631469800Z",
     "start_time": "2024-08-13T00:43:33.599511900Z"
    }
   },
   "id": "29a00c897186e952"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "  \"LR\": LinearRegression,\n",
    "  \"LgR\": LogisticRegression,  # classifier\n",
    "  \"DTR\": DecisionTreeRegressor,\n",
    "  \"DTC\": DecisionTreeClassifier,  # classifier\n",
    "  \"RFR\": RandomForestRegressor,\n",
    "  \"RFC\": RandomForestClassifier,  # classifier\n",
    "  \"SVR\": SVR,\n",
    "  \"SVM\": SVC,  # classifier\n",
    "  \"GBR\": GradientBoostingRegressor,\n",
    "  \"GBC\": GradientBoostingClassifier,  # classifier\n",
    "}\n",
    "\n",
    "def train_model(_model_key, _X_train, _y_train, **kwargs):\n",
    "  if _model_key not in models_dict.keys():\n",
    "    raise ValueError(f\"Model for key `{_model_key}` not found! Available keys: {', '.join(models_dict.keys())}\")\n",
    "  \n",
    "  model = models_dict[_model_key](**kwargs)\n",
    "  model.fit(_X_train, _y_train)\n",
    "  return model\n",
    "\n",
    "def evaluate_model(_model, _X_test, _y_test):\n",
    "  _predictions = _model.predict(_X_test)\n",
    "  _mse = mean_squared_error(_y_test, _predictions)\n",
    "  _mae = mean_absolute_error(_y_test, _predictions)\n",
    "  _r2 = r2_score(_y_test, _predictions)\n",
    "  print(f\"MSE: {_mse}, MAE: {_mae}, R2 Score: {_r2}\")\n",
    "  return _mse, _mae, _r2\n",
    "\n",
    "def evaluate_classification_model(_model, _X_test, _y_test):\n",
    "  _predictions = _model.predict(_X_test)\n",
    "  _accuracy = accuracy_score(_y_test, _predictions)\n",
    "  _precision = precision_score(_y_test, _predictions, zero_division=1)\n",
    "  _recall = recall_score(_y_test, _predictions)\n",
    "  _f1 = f1_score(_y_test, _predictions)\n",
    "  _conf_matrix = confusion_matrix(_y_test, _predictions)\n",
    "  return _accuracy, _precision, _recall, _f1, _conf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:35.330548400Z",
     "start_time": "2024-08-13T00:43:35.273507800Z"
    }
   },
   "id": "89d5821e50a02db"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:36.519687600Z",
     "start_time": "2024-08-13T00:43:36.486585200Z"
    }
   },
   "id": "984c6a931ba54aa4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation Score: 0.8273636162349054\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause overfitting\n",
    "param_grid = {\n",
    "  'n_estimators': [200, 500, 1000],         # Increase the number of trees\n",
    "  'max_depth': [None, 50, 100],             # Increase the tree depth\n",
    "  'min_samples_split': [2, 5],              # Reduce the minimum samples required to split a node\n",
    "  'min_samples_leaf': [1, 2],               # Reduce the minimum samples required at a leaf node\n",
    "  # 'max_features': [None, 'sqrt', 'log2'],   # Use all features or most features\n",
    "  # 'bootstrap': [False]                      # Disable bootstrap sampling\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=RandomForestClassifier(random_state=42),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T12:57:55.602768600Z",
     "start_time": "2024-08-12T12:53:46.747016500Z"
    }
   },
   "id": "8d0ee08254b2ccf4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-12T13:14:42.482589500Z",
     "start_time": "2024-08-12T12:57:55.651504800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Best Cross-Validation Score: 0.8214875751537138\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause overfitting\n",
    "param_grid = {\n",
    "  'n_estimators': [200, 500],         # Increase the number of trees\n",
    "  'max_depth': [50, 100],             # Increase the tree depth\n",
    "  'min_samples_split': [2, 5],              # Reduce the minimum samples required to split a node\n",
    "  'min_samples_leaf': [1, 2],               # Reduce the minimum samples required at a leaf node\n",
    "  # 'max_features': [None, 'sqrt', 'log2'],   # Use all features or most features\n",
    "  # 'bootstrap': [False]                      # Disable bootstrap sampling\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=GradientBoostingClassifier(random_state=42),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best Cross-Validation Score: 0.813363309658849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "315 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "46 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "43 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.81148979 0.81171121 0.81297157 0.81302267 0.81315893\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81147276 0.81171121 0.81297157 0.81302267 0.81315893\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81147276 0.81171121 0.81297157 0.81302267 0.81315893\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81321002 0.81326112 0.81334628 0.81332925 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81321002 0.81326112 0.81334628 0.81332925 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81321002 0.81326112 0.81334628 0.81334628 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81332925 0.81332925 0.81332925 0.81334628 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81331221 0.81332925 0.81332925 0.81336331 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81332925 0.81332925 0.81332925 0.81336331 0.81334628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81336331 0.81336331 0.81336331 0.81334628 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81334628 0.81334628 0.81336331 0.81334628 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81336331 0.81336331 0.81336331 0.81336331 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81334628 0.81336331 0.81336331 0.81336331 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81332925 0.81336331 0.81336331 0.81334628 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81336331 0.81332925 0.81336331 0.81336331 0.81336331\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause overfitting\n",
    "param_grid = {\n",
    "  'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "  'C': [0.01, 0.1, 1, 10, 100],\n",
    "  'solver': ['lbfgs', 'saga', 'liblinear'],\n",
    "  'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=LogisticRegression(),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T13:52:36.411728900Z",
     "start_time": "2024-08-12T13:52:34.143917700Z"
    }
   },
   "id": "306a74df0dd90bb3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}\n",
      "Best Cross-Validation Score: 0.8161055181215747\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause overfitting\n",
    "param_grid = {\n",
    "  'criterion': ['gini', 'entropy'],\n",
    "  'splitter': ['best', 'random'],\n",
    "  'max_depth': [None, 10, 20, 30],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'min_samples_leaf': [1, 2, 4],\n",
    "  'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=DecisionTreeClassifier(),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=5,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T13:55:30.467219300Z",
     "start_time": "2024-08-12T13:55:18.316344700Z"
    }
   },
   "id": "c63a4e2aa5b90eb3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.8136017577027234\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause underfitting\n",
    "param_grid = {\n",
    "  'n_estimators': [10, 20, 40, 100],               # Very few trees\n",
    "  'max_depth': [2, 3],                    # Shallow trees\n",
    "  'min_samples_split': [10, 20],          # High number of samples required to split\n",
    "  'min_samples_leaf': [10, 20],           # High number of samples required at a leaf node\n",
    "  'max_features': ['sqrt', 'log2']        # Limiting the number of features\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=RandomForestClassifier(random_state=42),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T14:04:21.911176100Z",
     "start_time": "2024-08-12T14:04:12.645240500Z"
    }
   },
   "id": "e8b962189c40097f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.8010832353993154\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause underfitting\n",
    "param_grid = {\n",
    "  'n_estimators': [10, 20, 40, 100],               # Very few trees\n",
    "  'max_depth': [2, 3],                    # Shallow trees\n",
    "  'learning_rate': [0.001, 0.01],         # Extremely low learning rates\n",
    "  'min_samples_split': [10, 20],          # High number of samples required to split\n",
    "  'min_samples_leaf': [10, 20]            # High number of samples required at a leaf node\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=GradientBoostingClassifier(random_state=42),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T14:05:09.505690500Z",
     "start_time": "2024-08-12T14:04:43.663363100Z"
    }
   },
   "id": "d6702bb7df07ffb2"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1e-06, 'max_iter': 10, 'penalty': None, 'solver': 'lbfgs'}\n",
      "Best Cross-Validation Score: 0.813363309658849\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause underfitting\n",
    "param_grid = {\n",
    "  'penalty': [None],                    # No regularization (in this context, it's underfitting)\n",
    "  'C': [1e-6, 1e-5],                      # Extremely high regularization strength\n",
    "  'solver': ['lbfgs'],                    # Standard solver with no additional complexity\n",
    "  'max_iter': [10, 20]                    # Very few iterations\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=LogisticRegression(),\n",
    "  param_grid=param_grid,\n",
    "  scoring='accuracy',\n",
    "  cv=3,  # Cross-validation fold\n",
    "  verbose=1,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T14:06:26.098442200Z",
     "start_time": "2024-08-12T14:06:25.752405900Z"
    }
   },
   "id": "7ca8a472302ce143"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'min_samples_split': 10, 'splitter': 'best'}\n",
      "Best Cross-Validation Score: 0.8052731081702519\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid to intentionally cause underfitting\n",
    "param_grid = {\n",
    "    'criterion': ['gini'],                  # Default criterion\n",
    "    'splitter': ['best'],                   # Default splitter\n",
    "    'max_depth': [1, 2],                    # Extremely shallow trees\n",
    "    'min_samples_split': [10, 20],          # High number of samples required to split\n",
    "    'min_samples_leaf': [10, 20],           # High number of samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2']        # Limiting the number of features\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # Cross-validation fold\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_is_flare_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T14:06:34.305870700Z",
     "start_time": "2024-08-12T14:06:34.004470500Z"
    }
   },
   "id": "ad40e022c6821a1e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def build_and_train_cnn_overfit(_X_train, _y_train, _X_test, _y_test,\n",
    "                                _epochs=100, _batch_size=16):\n",
    "  # Reshape input to be 3D [samples, timesteps, features] for CNN\n",
    "  X_train_cnn = np.expand_dims(_X_train, axis=2)\n",
    "  X_test_cnn = np.expand_dims(_X_test, axis=2)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2])))\n",
    "  model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy',])\n",
    "\n",
    "  # Increase the number of epochs and reduce dropout to overfit\n",
    "  model.fit(X_train_cnn, _y_train, validation_data=(X_test_cnn, _y_test), epochs=_epochs, batch_size=_batch_size)\n",
    "\n",
    "  return model\n",
    "\n",
    "def build_and_train_lstm_overfit(_X_train, _y_train, _X_test, _y_test,\n",
    "                                 _epochs=100, _batch_size=16):\n",
    "  # Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
    "  X_train_lstm = np.expand_dims(_X_train, axis=1)\n",
    "  X_test_lstm = np.expand_dims(_X_test, axis=1)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(100, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))\n",
    "  model.add(LSTM(100, return_sequences=True))\n",
    "  model.add(LSTM(100, return_sequences=False))\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy',])\n",
    "\n",
    "  # Increase the number of epochs and reduce dropout to overfit\n",
    "  model.fit(X_train_lstm, _y_train, validation_data=(X_test_lstm, _y_test), epochs=_epochs, batch_size=_batch_size)\n",
    "\n",
    "  return model\n",
    "\n",
    "def build_and_train_cnn_underfit(_X_train, _y_train, _X_test, _y_test,\n",
    "                                 _epochs=5, _batch_size=64):\n",
    "  # Reshape input to be 3D [samples, timesteps, features] for CNN\n",
    "  X_train_cnn = np.expand_dims(_X_train, axis=2)\n",
    "  X_test_cnn = np.expand_dims(_X_test, axis=2)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=16, kernel_size=5, activation='relu', input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2])))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(10, activation='relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy',])\n",
    "\n",
    "  # Reduce the number of epochs and increase dropout to underfit\n",
    "  model.fit(X_train_cnn, _y_train, validation_data=(X_test_cnn, _y_test), epochs=_epochs, batch_size=_batch_size)\n",
    "\n",
    "  return model\n",
    "\n",
    "def build_and_train_lstm_underfit(_X_train, _y_train, _X_test, _y_test,\n",
    "                                  _epochs=5, _batch_size=64):\n",
    "  # Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
    "  X_train_lstm = np.expand_dims(_X_train, axis=1)\n",
    "  X_test_lstm = np.expand_dims(_X_test, axis=1)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(10, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=False))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy',])\n",
    "\n",
    "  # Reduce the number of epochs and increase dropout to underfit\n",
    "  model.fit(X_train_lstm, _y_train, validation_data=(X_test_lstm, _y_test), epochs=_epochs, batch_size=_batch_size)\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:43:46.656864700Z",
     "start_time": "2024-08-13T00:43:46.644857800Z"
    }
   },
   "id": "f309be053c622842"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723506489.858502  291935 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-13 00:48:10.025974: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8122 - loss: 0.4278 - val_accuracy: 0.8154 - val_loss: 0.4124\n",
      "Epoch 2/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8201 - loss: 0.4109 - val_accuracy: 0.8158 - val_loss: 0.4226\n",
      "Epoch 3/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8202 - loss: 0.4080 - val_accuracy: 0.8157 - val_loss: 0.4113\n",
      "Epoch 4/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8188 - loss: 0.4070 - val_accuracy: 0.8199 - val_loss: 0.4095\n",
      "Epoch 5/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8183 - loss: 0.4089 - val_accuracy: 0.8192 - val_loss: 0.4076\n",
      "Epoch 6/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8179 - loss: 0.4109 - val_accuracy: 0.8182 - val_loss: 0.4087\n",
      "Epoch 7/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8236 - loss: 0.4026 - val_accuracy: 0.8144 - val_loss: 0.4219\n",
      "Epoch 8/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8228 - loss: 0.4012 - val_accuracy: 0.8195 - val_loss: 0.4063\n",
      "Epoch 9/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8213 - loss: 0.4038 - val_accuracy: 0.8209 - val_loss: 0.4075\n",
      "Epoch 10/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8282 - loss: 0.3979 - val_accuracy: 0.8197 - val_loss: 0.4085\n",
      "Epoch 11/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8223 - loss: 0.4038 - val_accuracy: 0.8211 - val_loss: 0.4072\n",
      "Epoch 12/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8234 - loss: 0.3983 - val_accuracy: 0.8200 - val_loss: 0.4061\n",
      "Epoch 13/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8235 - loss: 0.3958 - val_accuracy: 0.8199 - val_loss: 0.4061\n",
      "Epoch 14/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 4ms/step - accuracy: 0.8242 - loss: 0.3950 - val_accuracy: 0.8217 - val_loss: 0.4063\n",
      "Epoch 15/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8261 - loss: 0.3931 - val_accuracy: 0.8216 - val_loss: 0.4052\n",
      "Epoch 16/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8266 - loss: 0.3936 - val_accuracy: 0.8208 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8238 - loss: 0.3982 - val_accuracy: 0.8225 - val_loss: 0.4057\n",
      "Epoch 18/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8283 - loss: 0.3928 - val_accuracy: 0.8202 - val_loss: 0.4058\n",
      "Epoch 19/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8300 - loss: 0.3890 - val_accuracy: 0.8211 - val_loss: 0.4036\n",
      "Epoch 20/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8296 - loss: 0.3886 - val_accuracy: 0.8197 - val_loss: 0.4062\n",
      "Epoch 21/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8299 - loss: 0.3872 - val_accuracy: 0.8198 - val_loss: 0.4045\n",
      "Epoch 22/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8320 - loss: 0.3872 - val_accuracy: 0.8220 - val_loss: 0.4029\n",
      "Epoch 23/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8299 - loss: 0.3897 - val_accuracy: 0.8202 - val_loss: 0.4066\n",
      "Epoch 24/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8307 - loss: 0.3892 - val_accuracy: 0.8196 - val_loss: 0.4045\n",
      "Epoch 25/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8324 - loss: 0.3829 - val_accuracy: 0.8213 - val_loss: 0.4063\n",
      "Epoch 26/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8293 - loss: 0.3899 - val_accuracy: 0.8225 - val_loss: 0.4092\n",
      "Epoch 27/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8324 - loss: 0.3853 - val_accuracy: 0.8207 - val_loss: 0.4106\n",
      "Epoch 28/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8340 - loss: 0.3826 - val_accuracy: 0.8190 - val_loss: 0.4087\n",
      "Epoch 29/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8342 - loss: 0.3837 - val_accuracy: 0.8196 - val_loss: 0.4067\n",
      "Epoch 30/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8327 - loss: 0.3846 - val_accuracy: 0.8193 - val_loss: 0.4113\n",
      "Epoch 31/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8337 - loss: 0.3851 - val_accuracy: 0.8189 - val_loss: 0.4132\n",
      "Epoch 32/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8355 - loss: 0.3789 - val_accuracy: 0.8163 - val_loss: 0.4098\n",
      "Epoch 33/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8331 - loss: 0.3807 - val_accuracy: 0.8194 - val_loss: 0.4099\n",
      "Epoch 34/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 5ms/step - accuracy: 0.8356 - loss: 0.3778 - val_accuracy: 0.8163 - val_loss: 0.4136\n",
      "Epoch 35/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8361 - loss: 0.3794 - val_accuracy: 0.8197 - val_loss: 0.4161\n",
      "Epoch 36/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8364 - loss: 0.3764 - val_accuracy: 0.8178 - val_loss: 0.4129\n",
      "Epoch 37/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8400 - loss: 0.3753 - val_accuracy: 0.8165 - val_loss: 0.4169\n",
      "Epoch 38/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8373 - loss: 0.3764 - val_accuracy: 0.8181 - val_loss: 0.4164\n",
      "Epoch 39/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8374 - loss: 0.3748 - val_accuracy: 0.8193 - val_loss: 0.4211\n",
      "Epoch 40/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8414 - loss: 0.3696 - val_accuracy: 0.8144 - val_loss: 0.4161\n",
      "Epoch 41/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8407 - loss: 0.3693 - val_accuracy: 0.8163 - val_loss: 0.4161\n",
      "Epoch 42/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8397 - loss: 0.3717 - val_accuracy: 0.8152 - val_loss: 0.4263\n",
      "Epoch 43/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8414 - loss: 0.3698 - val_accuracy: 0.8167 - val_loss: 0.4145\n",
      "Epoch 44/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8400 - loss: 0.3693 - val_accuracy: 0.8210 - val_loss: 0.4187\n",
      "Epoch 45/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8415 - loss: 0.3665 - val_accuracy: 0.8169 - val_loss: 0.4177\n",
      "Epoch 46/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 5ms/step - accuracy: 0.8429 - loss: 0.3681 - val_accuracy: 0.8137 - val_loss: 0.4199\n",
      "Epoch 47/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8436 - loss: 0.3666 - val_accuracy: 0.8146 - val_loss: 0.4261\n",
      "Epoch 48/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8445 - loss: 0.3645 - val_accuracy: 0.8176 - val_loss: 0.4218\n",
      "Epoch 49/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8454 - loss: 0.3623 - val_accuracy: 0.8148 - val_loss: 0.4209\n",
      "Epoch 50/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 5ms/step - accuracy: 0.8449 - loss: 0.3611 - val_accuracy: 0.8136 - val_loss: 0.4267\n",
      "Epoch 51/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8442 - loss: 0.3637 - val_accuracy: 0.8127 - val_loss: 0.4332\n",
      "Epoch 52/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8482 - loss: 0.3565 - val_accuracy: 0.8062 - val_loss: 0.4273\n",
      "Epoch 53/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 4ms/step - accuracy: 0.8487 - loss: 0.3565 - val_accuracy: 0.8140 - val_loss: 0.4315\n",
      "Epoch 54/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8454 - loss: 0.3620 - val_accuracy: 0.8108 - val_loss: 0.4413\n",
      "Epoch 55/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8446 - loss: 0.3636 - val_accuracy: 0.8137 - val_loss: 0.4572\n",
      "Epoch 56/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8505 - loss: 0.3538 - val_accuracy: 0.8099 - val_loss: 0.4323\n",
      "Epoch 57/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 4ms/step - accuracy: 0.8470 - loss: 0.3590 - val_accuracy: 0.8131 - val_loss: 0.4519\n",
      "Epoch 58/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8470 - loss: 0.3607 - val_accuracy: 0.8110 - val_loss: 0.4461\n",
      "Epoch 59/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8496 - loss: 0.3551 - val_accuracy: 0.8174 - val_loss: 0.4406\n",
      "Epoch 60/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8501 - loss: 0.3565 - val_accuracy: 0.8151 - val_loss: 0.4494\n",
      "Epoch 61/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8522 - loss: 0.3491 - val_accuracy: 0.8133 - val_loss: 0.4387\n",
      "Epoch 62/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8498 - loss: 0.3532 - val_accuracy: 0.8093 - val_loss: 0.4413\n",
      "Epoch 63/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8466 - loss: 0.3596 - val_accuracy: 0.8093 - val_loss: 0.4414\n",
      "Epoch 64/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8501 - loss: 0.3548 - val_accuracy: 0.8143 - val_loss: 0.4541\n",
      "Epoch 65/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8491 - loss: 0.3543 - val_accuracy: 0.8116 - val_loss: 0.4452\n",
      "Epoch 66/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8536 - loss: 0.3491 - val_accuracy: 0.8155 - val_loss: 0.4567\n",
      "Epoch 67/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8532 - loss: 0.3510 - val_accuracy: 0.8103 - val_loss: 0.4551\n",
      "Epoch 68/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8493 - loss: 0.3502 - val_accuracy: 0.8056 - val_loss: 0.4675\n",
      "Epoch 69/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8524 - loss: 0.3484 - val_accuracy: 0.8117 - val_loss: 0.4500\n",
      "Epoch 70/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8539 - loss: 0.3468 - val_accuracy: 0.8134 - val_loss: 0.4471\n",
      "Epoch 71/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8519 - loss: 0.3471 - val_accuracy: 0.8118 - val_loss: 0.4437\n",
      "Epoch 72/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8526 - loss: 0.3459 - val_accuracy: 0.8097 - val_loss: 0.4632\n",
      "Epoch 73/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8560 - loss: 0.3442 - val_accuracy: 0.8140 - val_loss: 0.4657\n",
      "Epoch 74/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8565 - loss: 0.3437 - val_accuracy: 0.8122 - val_loss: 0.4852\n",
      "Epoch 75/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8530 - loss: 0.3482 - val_accuracy: 0.8133 - val_loss: 0.4488\n",
      "Epoch 76/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8548 - loss: 0.3435 - val_accuracy: 0.8093 - val_loss: 0.4696\n",
      "Epoch 77/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8565 - loss: 0.3403 - val_accuracy: 0.8105 - val_loss: 0.4766\n",
      "Epoch 78/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8560 - loss: 0.3418 - val_accuracy: 0.8088 - val_loss: 0.4670\n",
      "Epoch 79/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8581 - loss: 0.3405 - val_accuracy: 0.8104 - val_loss: 0.4853\n",
      "Epoch 80/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8580 - loss: 0.3391 - val_accuracy: 0.8071 - val_loss: 0.5030\n",
      "Epoch 81/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8566 - loss: 0.3423 - val_accuracy: 0.8097 - val_loss: 0.4855\n",
      "Epoch 82/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8566 - loss: 0.3378 - val_accuracy: 0.8085 - val_loss: 0.4935\n",
      "Epoch 83/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8588 - loss: 0.3355 - val_accuracy: 0.8099 - val_loss: 0.4817\n",
      "Epoch 84/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8556 - loss: 0.3436 - val_accuracy: 0.8085 - val_loss: 0.5124\n",
      "Epoch 85/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8594 - loss: 0.3351 - val_accuracy: 0.8097 - val_loss: 0.4846\n",
      "Epoch 86/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8587 - loss: 0.3369 - val_accuracy: 0.8118 - val_loss: 0.4907\n",
      "Epoch 87/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8624 - loss: 0.3314 - val_accuracy: 0.8128 - val_loss: 0.4790\n",
      "Epoch 88/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8608 - loss: 0.3322 - val_accuracy: 0.8093 - val_loss: 0.5180\n",
      "Epoch 89/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8586 - loss: 0.3379 - val_accuracy: 0.8066 - val_loss: 0.4962\n",
      "Epoch 90/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8610 - loss: 0.3353 - val_accuracy: 0.8088 - val_loss: 0.5268\n",
      "Epoch 91/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8595 - loss: 0.3339 - val_accuracy: 0.8121 - val_loss: 0.5099\n",
      "Epoch 92/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8606 - loss: 0.3332 - val_accuracy: 0.8082 - val_loss: 0.5506\n",
      "Epoch 93/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8617 - loss: 0.3338 - val_accuracy: 0.8122 - val_loss: 0.5579\n",
      "Epoch 94/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8601 - loss: 0.3328 - val_accuracy: 0.8066 - val_loss: 0.5332\n",
      "Epoch 95/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8590 - loss: 0.3366 - val_accuracy: 0.8056 - val_loss: 0.5365\n",
      "Epoch 96/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8614 - loss: 0.3329 - val_accuracy: 0.8073 - val_loss: 0.5228\n",
      "Epoch 97/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8608 - loss: 0.3306 - val_accuracy: 0.8110 - val_loss: 0.5116\n",
      "Epoch 98/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8614 - loss: 0.3297 - val_accuracy: 0.8070 - val_loss: 0.5381\n",
      "Epoch 99/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8607 - loss: 0.3309 - val_accuracy: 0.8117 - val_loss: 0.5748\n",
      "Epoch 100/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 4ms/step - accuracy: 0.8614 - loss: 0.3309 - val_accuracy: 0.8048 - val_loss: 0.5143\n"
     ]
    }
   ],
   "source": [
    "cnn_overfit_model = build_and_train_cnn_overfit(X_train_scaled, y_is_flare_train,\n",
    "                                                X_test_scaled, y_is_flare_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:11:43.450953700Z",
     "start_time": "2024-08-12T23:48:09.652752900Z"
    }
   },
   "id": "cd72a0d724f1bced"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723509831.643803  322538 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-13 01:43:51.671047: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.8106 - loss: 0.4299 - val_accuracy: 0.8167 - val_loss: 0.4130\n",
      "Epoch 2/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8180 - loss: 0.4106 - val_accuracy: 0.8186 - val_loss: 0.4146\n",
      "Epoch 3/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8222 - loss: 0.4074 - val_accuracy: 0.8180 - val_loss: 0.4092\n",
      "Epoch 4/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8201 - loss: 0.4099 - val_accuracy: 0.8151 - val_loss: 0.4134\n",
      "Epoch 5/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8201 - loss: 0.4090 - val_accuracy: 0.8180 - val_loss: 0.4080\n",
      "Epoch 6/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8199 - loss: 0.4074 - val_accuracy: 0.8166 - val_loss: 0.4090\n",
      "Epoch 7/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8229 - loss: 0.4032 - val_accuracy: 0.8182 - val_loss: 0.4094\n",
      "Epoch 8/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8231 - loss: 0.4028 - val_accuracy: 0.8165 - val_loss: 0.4072\n",
      "Epoch 9/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8225 - loss: 0.4074 - val_accuracy: 0.8177 - val_loss: 0.4086\n",
      "Epoch 10/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8234 - loss: 0.4019 - val_accuracy: 0.8180 - val_loss: 0.4092\n",
      "Epoch 11/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8236 - loss: 0.4045 - val_accuracy: 0.8169 - val_loss: 0.4075\n",
      "Epoch 12/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8237 - loss: 0.4013 - val_accuracy: 0.8174 - val_loss: 0.4077\n",
      "Epoch 13/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8211 - loss: 0.4061 - val_accuracy: 0.8189 - val_loss: 0.4085\n",
      "Epoch 14/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8224 - loss: 0.4028 - val_accuracy: 0.8180 - val_loss: 0.4069\n",
      "Epoch 15/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8215 - loss: 0.4053 - val_accuracy: 0.8178 - val_loss: 0.4075\n",
      "Epoch 16/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8216 - loss: 0.4022 - val_accuracy: 0.8178 - val_loss: 0.4082\n",
      "Epoch 17/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8226 - loss: 0.4045 - val_accuracy: 0.8181 - val_loss: 0.4075\n",
      "Epoch 18/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8201 - loss: 0.4065 - val_accuracy: 0.8186 - val_loss: 0.4087\n",
      "Epoch 19/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8219 - loss: 0.4049 - val_accuracy: 0.8180 - val_loss: 0.4075\n",
      "Epoch 20/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8220 - loss: 0.4037 - val_accuracy: 0.8187 - val_loss: 0.4076\n",
      "Epoch 21/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8241 - loss: 0.3985 - val_accuracy: 0.8186 - val_loss: 0.4063\n",
      "Epoch 22/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.8221 - loss: 0.4035 - val_accuracy: 0.8182 - val_loss: 0.4072\n",
      "Epoch 23/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8232 - loss: 0.4007 - val_accuracy: 0.8186 - val_loss: 0.4076\n",
      "Epoch 24/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8241 - loss: 0.4006 - val_accuracy: 0.8182 - val_loss: 0.4068\n",
      "Epoch 25/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8221 - loss: 0.4009 - val_accuracy: 0.8189 - val_loss: 0.4066\n",
      "Epoch 26/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8281 - loss: 0.3937 - val_accuracy: 0.8182 - val_loss: 0.4092\n",
      "Epoch 27/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8245 - loss: 0.3977 - val_accuracy: 0.8167 - val_loss: 0.4121\n",
      "Epoch 28/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8250 - loss: 0.3954 - val_accuracy: 0.8182 - val_loss: 0.4083\n",
      "Epoch 29/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8238 - loss: 0.3974 - val_accuracy: 0.8195 - val_loss: 0.4074\n",
      "Epoch 30/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8253 - loss: 0.3931 - val_accuracy: 0.8195 - val_loss: 0.4091\n",
      "Epoch 31/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8254 - loss: 0.3970 - val_accuracy: 0.8193 - val_loss: 0.4111\n",
      "Epoch 32/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8240 - loss: 0.3959 - val_accuracy: 0.8203 - val_loss: 0.4105\n",
      "Epoch 33/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8266 - loss: 0.3935 - val_accuracy: 0.8193 - val_loss: 0.4112\n",
      "Epoch 34/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8267 - loss: 0.3929 - val_accuracy: 0.8170 - val_loss: 0.4104\n",
      "Epoch 35/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8262 - loss: 0.3936 - val_accuracy: 0.8189 - val_loss: 0.4109\n",
      "Epoch 36/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8315 - loss: 0.3871 - val_accuracy: 0.8197 - val_loss: 0.4093\n",
      "Epoch 37/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8323 - loss: 0.3841 - val_accuracy: 0.8187 - val_loss: 0.4109\n",
      "Epoch 38/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8299 - loss: 0.3893 - val_accuracy: 0.8219 - val_loss: 0.4124\n",
      "Epoch 39/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8293 - loss: 0.3860 - val_accuracy: 0.8187 - val_loss: 0.4127\n",
      "Epoch 40/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8290 - loss: 0.3837 - val_accuracy: 0.8195 - val_loss: 0.4147\n",
      "Epoch 41/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8320 - loss: 0.3803 - val_accuracy: 0.8187 - val_loss: 0.4166\n",
      "Epoch 42/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8306 - loss: 0.3827 - val_accuracy: 0.8165 - val_loss: 0.4186\n",
      "Epoch 43/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8343 - loss: 0.3806 - val_accuracy: 0.8151 - val_loss: 0.4203\n",
      "Epoch 44/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8314 - loss: 0.3793 - val_accuracy: 0.8146 - val_loss: 0.4259\n",
      "Epoch 45/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8340 - loss: 0.3756 - val_accuracy: 0.8165 - val_loss: 0.4213\n",
      "Epoch 46/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8359 - loss: 0.3756 - val_accuracy: 0.8166 - val_loss: 0.4213\n",
      "Epoch 47/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8359 - loss: 0.3734 - val_accuracy: 0.8152 - val_loss: 0.4254\n",
      "Epoch 48/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8366 - loss: 0.3725 - val_accuracy: 0.8127 - val_loss: 0.4297\n",
      "Epoch 49/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 2ms/step - accuracy: 0.8371 - loss: 0.3681 - val_accuracy: 0.8118 - val_loss: 0.4360\n",
      "Epoch 50/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8368 - loss: 0.3689 - val_accuracy: 0.8106 - val_loss: 0.4426\n",
      "Epoch 51/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8416 - loss: 0.3632 - val_accuracy: 0.8120 - val_loss: 0.4514\n",
      "Epoch 52/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8404 - loss: 0.3603 - val_accuracy: 0.8142 - val_loss: 0.4445\n",
      "Epoch 53/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8395 - loss: 0.3628 - val_accuracy: 0.8130 - val_loss: 0.4621\n",
      "Epoch 54/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8406 - loss: 0.3610 - val_accuracy: 0.8116 - val_loss: 0.4516\n",
      "Epoch 55/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8415 - loss: 0.3583 - val_accuracy: 0.8116 - val_loss: 0.4668\n",
      "Epoch 56/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8461 - loss: 0.3535 - val_accuracy: 0.8088 - val_loss: 0.4714\n",
      "Epoch 57/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8476 - loss: 0.3498 - val_accuracy: 0.8053 - val_loss: 0.4987\n",
      "Epoch 58/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8452 - loss: 0.3493 - val_accuracy: 0.8057 - val_loss: 0.4734\n",
      "Epoch 59/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8487 - loss: 0.3445 - val_accuracy: 0.8082 - val_loss: 0.4779\n",
      "Epoch 60/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8503 - loss: 0.3439 - val_accuracy: 0.8048 - val_loss: 0.4958\n",
      "Epoch 61/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8515 - loss: 0.3403 - val_accuracy: 0.8022 - val_loss: 0.5128\n",
      "Epoch 62/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8534 - loss: 0.3363 - val_accuracy: 0.8042 - val_loss: 0.5200\n",
      "Epoch 63/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8525 - loss: 0.3336 - val_accuracy: 0.8022 - val_loss: 0.5468\n",
      "Epoch 64/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8548 - loss: 0.3297 - val_accuracy: 0.8025 - val_loss: 0.5393\n",
      "Epoch 65/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8569 - loss: 0.3261 - val_accuracy: 0.8006 - val_loss: 0.5522\n",
      "Epoch 66/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8562 - loss: 0.3250 - val_accuracy: 0.8018 - val_loss: 0.5649\n",
      "Epoch 67/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8613 - loss: 0.3212 - val_accuracy: 0.7981 - val_loss: 0.5511\n",
      "Epoch 68/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8595 - loss: 0.3190 - val_accuracy: 0.7966 - val_loss: 0.6011\n",
      "Epoch 69/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8624 - loss: 0.3134 - val_accuracy: 0.7996 - val_loss: 0.5921\n",
      "Epoch 70/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8636 - loss: 0.3085 - val_accuracy: 0.7983 - val_loss: 0.6052\n",
      "Epoch 71/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 2ms/step - accuracy: 0.8670 - loss: 0.3058 - val_accuracy: 0.7975 - val_loss: 0.6289\n",
      "Epoch 72/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8651 - loss: 0.3062 - val_accuracy: 0.8018 - val_loss: 0.6242\n",
      "Epoch 73/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8700 - loss: 0.2976 - val_accuracy: 0.7937 - val_loss: 0.6298\n",
      "Epoch 74/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8686 - loss: 0.2995 - val_accuracy: 0.7963 - val_loss: 0.6369\n",
      "Epoch 75/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8737 - loss: 0.2940 - val_accuracy: 0.7934 - val_loss: 0.6642\n",
      "Epoch 76/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8726 - loss: 0.2907 - val_accuracy: 0.7937 - val_loss: 0.6585\n",
      "Epoch 77/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8726 - loss: 0.2923 - val_accuracy: 0.7962 - val_loss: 0.6997\n",
      "Epoch 78/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8753 - loss: 0.2868 - val_accuracy: 0.7935 - val_loss: 0.6785\n",
      "Epoch 79/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8777 - loss: 0.2818 - val_accuracy: 0.7945 - val_loss: 0.7148\n",
      "Epoch 80/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8816 - loss: 0.2759 - val_accuracy: 0.7943 - val_loss: 0.7299\n",
      "Epoch 81/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8784 - loss: 0.2778 - val_accuracy: 0.7926 - val_loss: 0.7501\n",
      "Epoch 82/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8813 - loss: 0.2738 - val_accuracy: 0.7941 - val_loss: 0.7982\n",
      "Epoch 83/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8857 - loss: 0.2664 - val_accuracy: 0.7917 - val_loss: 0.7841\n",
      "Epoch 84/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8845 - loss: 0.2654 - val_accuracy: 0.7913 - val_loss: 0.7757\n",
      "Epoch 85/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8874 - loss: 0.2610 - val_accuracy: 0.7936 - val_loss: 0.8165\n",
      "Epoch 86/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8869 - loss: 0.2585 - val_accuracy: 0.7881 - val_loss: 0.8227\n",
      "Epoch 87/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8906 - loss: 0.2531 - val_accuracy: 0.7942 - val_loss: 0.8337\n",
      "Epoch 88/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8902 - loss: 0.2555 - val_accuracy: 0.7926 - val_loss: 0.8821\n",
      "Epoch 89/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8936 - loss: 0.2474 - val_accuracy: 0.7887 - val_loss: 0.9191\n",
      "Epoch 90/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8977 - loss: 0.2406 - val_accuracy: 0.7905 - val_loss: 0.9376\n",
      "Epoch 91/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8954 - loss: 0.2443 - val_accuracy: 0.7898 - val_loss: 0.9921\n",
      "Epoch 92/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8970 - loss: 0.2353 - val_accuracy: 0.7930 - val_loss: 1.0462\n",
      "Epoch 93/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8963 - loss: 0.2371 - val_accuracy: 0.7871 - val_loss: 1.0080\n",
      "Epoch 94/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.8976 - loss: 0.2354 - val_accuracy: 0.7880 - val_loss: 1.0287\n",
      "Epoch 95/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9024 - loss: 0.2292 - val_accuracy: 0.7808 - val_loss: 1.0462\n",
      "Epoch 96/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9052 - loss: 0.2227 - val_accuracy: 0.7877 - val_loss: 1.0591\n",
      "Epoch 97/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9040 - loss: 0.2222 - val_accuracy: 0.7857 - val_loss: 1.0839\n",
      "Epoch 98/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9058 - loss: 0.2188 - val_accuracy: 0.7842 - val_loss: 1.0854\n",
      "Epoch 99/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9075 - loss: 0.2121 - val_accuracy: 0.7832 - val_loss: 1.0681\n",
      "Epoch 100/100\n",
      "\u001B[1m3670/3670\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 2ms/step - accuracy: 0.9086 - loss: 0.2142 - val_accuracy: 0.7819 - val_loss: 1.1763\n"
     ]
    }
   ],
   "source": [
    "lstm_overfit_model = build_and_train_lstm_overfit(X_train_scaled, y_is_flare_train,\n",
    "                                                  X_test_scaled, y_is_flare_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:55:18.615918200Z",
     "start_time": "2024-08-13T00:43:51.735839500Z"
    }
   },
   "id": "488c89a38d661454"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debashis/works/dissertation/env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7704 - loss: 0.4956 - val_accuracy: 0.8121 - val_loss: 0.4234\n",
      "Epoch 2/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.8031 - loss: 0.4428 - val_accuracy: 0.8124 - val_loss: 0.4220\n",
      "Epoch 3/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.8064 - loss: 0.4331 - val_accuracy: 0.8108 - val_loss: 0.4203\n",
      "Epoch 4/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.8092 - loss: 0.4281 - val_accuracy: 0.8122 - val_loss: 0.4190\n",
      "Epoch 5/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.8119 - loss: 0.4260 - val_accuracy: 0.8127 - val_loss: 0.4185\n"
     ]
    }
   ],
   "source": [
    "cnn_underfit_model = build_and_train_cnn_underfit(X_train_scaled, y_is_flare_train,\n",
    "                                                X_test_scaled, y_is_flare_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:55:27.840382600Z",
     "start_time": "2024-08-13T00:55:18.618899100Z"
    }
   },
   "id": "125a7c401cea58f1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.7423 - loss: 0.5500 - val_accuracy: 0.8157 - val_loss: 0.4190\n",
      "Epoch 2/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 956us/step - accuracy: 0.8134 - loss: 0.4372 - val_accuracy: 0.8178 - val_loss: 0.4140\n",
      "Epoch 3/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 960us/step - accuracy: 0.8183 - loss: 0.4283 - val_accuracy: 0.8182 - val_loss: 0.4121\n",
      "Epoch 4/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 938us/step - accuracy: 0.8172 - loss: 0.4203 - val_accuracy: 0.8189 - val_loss: 0.4108\n",
      "Epoch 5/5\n",
      "\u001B[1m918/918\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.8118 - loss: 0.4260 - val_accuracy: 0.8190 - val_loss: 0.4100\n"
     ]
    }
   ],
   "source": [
    "lstm_underfit_model = build_and_train_lstm_underfit(X_train_scaled, y_is_flare_train,\n",
    "                                                  X_test_scaled, y_is_flare_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-13T00:55:33.390173300Z",
     "start_time": "2024-08-13T00:55:27.834672400Z"
    }
   },
   "id": "afbfa373765dcc64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c1ba8c04b57d01c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
